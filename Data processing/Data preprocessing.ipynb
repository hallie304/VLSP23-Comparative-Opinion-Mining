{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from modelUtils import load_segmenter   \n",
    "import re"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T10:45:16.304545200Z",
     "start_time": "2023-10-25T10:45:15.942913700Z"
    }
   },
   "id": "2a8ed97ba445949"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "only_files = [f for f in os.listdir(\"Data/VLSP2023_ComOM_training_v2/VLSP2023_ComOM_training_v2\") if\n",
    "              os.path.isfile(os.path.join(\"Data/VLSP2023_ComOM_training_v2/VLSP2023_ComOM_training_v2\", f))]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T10:45:20.094989600Z",
     "start_time": "2023-10-25T10:45:20.083954500Z"
    }
   },
   "id": "a8029f534f70d17c"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "segmenter = load_segmenter()\n",
    "os.chdir(\"../\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T09:43:52.330754100Z",
     "start_time": "2023-10-24T09:43:37.505341700Z"
    }
   },
   "id": "71552531bba623ad"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ói']\n"
     ]
    }
   ],
   "source": [
    "print(segmenter.word_segment('ói'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T16:11:27.668504900Z",
     "start_time": "2023-10-23T16:11:27.663997600Z"
    }
   },
   "id": "819b5e67aac4d354"
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "error = []\n",
    "smentederr = []\n",
    "type_of_compare = [\"DIF\", \"EQL\", \"SUP+\", \"SUP-\", \"SUP\", \"COM+\", \"COM-\", \"COM\"]\n",
    "data_frame = {\"content\": [], \"comparative\": [], \"subject\": [], \"object\": [], \"aspect\": [], \"predicate\": [], \"label\": [], \"NER\": []}\n",
    "pred_label = dict()\n",
    "dct_index_out_of_range = {}\n",
    "special_char = {'oá':'óa','oã':'õa','oả':'ỏa','oà':'òa','oạ':'ọa','oé':'óe','oè':'òe','oẻ':'ỏe','oẽ':'õe','oẹ':'ọe'}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T15:54:46.529595700Z",
     "start_time": "2023-10-24T15:54:46.514771300Z"
    }
   },
   "id": "f98be20620788a0b"
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "def preprocessing_with_BIO(filename):\n",
    "    data_row = []\n",
    "    labeled_row = dict()\n",
    "    data = []\n",
    "    with (open('Data/VLSP2023_ComOM_training_v2/VLSP2023_ComOM_training_v2/' + filename, 'r', encoding=\"utf-8\") as f):\n",
    "        row = f.readline()\n",
    "        while row != \"\":\n",
    "            split_row = row.split(\"\\t\")\n",
    "            if len(split_row) > 1:\n",
    "                r = split_row[1]\n",
    "            else:\n",
    "                r = row\n",
    "            r = r.replace(\"\\n\", \"\")\n",
    "            data_row.append(r)\n",
    "            row = f.readline()\n",
    "    f.close()\n",
    "    filename = filename[:-4]\n",
    "    del f\n",
    "    j = 0\n",
    "    for i in range(len(data_row) - 1, -1, -1):\n",
    "        if data_row[i] == \"\":\n",
    "            data_row.remove(data_row[i])\n",
    "    for i in range(len(data_row) - 1):\n",
    "        if re.match(\"^\\{\\\"subject\\\": \\[\", data_row[i + 1]) and re.match(\"^\\{\\\"subject\\\": \\[\", data_row[i]):\n",
    "            row = eval(data_row[i + 1])\n",
    "            labeled_row[data_row[j]].append(row)\n",
    "        elif re.match(\"^\\{\\\"subject\\\": \\[\", data_row[i + 1]):\n",
    "            j = i\n",
    "            row = eval(data_row[i + 1])\n",
    "            labeled_row[data_row[j]] = [row]\n",
    "    for i in data_row:\n",
    "        if re.match(\"^\\{\\\"subject\\\": \\[\", i) is None:\n",
    "            data.append(i)\n",
    "    del data_row\n",
    "    del j\n",
    "    del row\n",
    "    for i in data:\n",
    "        sentence_label = []\n",
    "        key = 0\n",
    "        subj = []\n",
    "        obj = []\n",
    "        asp = []\n",
    "        pred = []\n",
    "        lab = []\n",
    "        w = i.split(\" \")\n",
    "        label = [0 for k in range(len(w))]\n",
    "        if i in labeled_row.keys():\n",
    "            key = 1\n",
    "            for k in range(len(labeled_row.get(i))):\n",
    "                list_dct = labeled_row.get(i)\n",
    "                if type(list_dct[k][\"subject\"]) == str:\n",
    "                    continue\n",
    "                for j in list_dct[k].keys():\n",
    "                    arr = list_dct[k].get(j)\n",
    "                    consecutive = []\n",
    "                    if j == \"label\":\n",
    "                        continue\n",
    "                    for e in range(len(arr)):\n",
    "                        consecutive.append(int(arr[e][:arr[e].find(\"&\")]))\n",
    "                        arr[e] = re.sub(\"^[0-9]+&&\", \"\", arr[e])\n",
    "                    s = \"_\".join(arr)\n",
    "                    list_dct[k][j] = s\n",
    "                    for q in range(len(consecutive)):\n",
    "                        if j == \"subject\":\n",
    "                            if q == 0:\n",
    "                                label[consecutive[q] - 1] = 1\n",
    "                            else:\n",
    "                                label[consecutive[q] - 1] = 2\n",
    "                        elif j == \"object\":\n",
    "                            if q == 0:\n",
    "                                label[consecutive[q] - 1] = 3\n",
    "                            else:\n",
    "                                label[consecutive[q] - 1] = 4\n",
    "                        elif j == \"aspect\":\n",
    "                            if q == 0:\n",
    "                                label[consecutive[q] - 1] = 5\n",
    "                            else:\n",
    "                                label[consecutive[q] - 1] = 6\n",
    "                        elif j == \"predicate\":\n",
    "                            if q == 0:\n",
    "                                label[consecutive[q] - 1] = 7\n",
    "                            else:\n",
    "                                label[consecutive[q] - 1] = 8\n",
    "                sentence_label.append(label)\n",
    "                subj.append(list_dct[k][\"subject\"])\n",
    "                obj.append(list_dct[k][\"object\"])\n",
    "                pred.append(list_dct[k][\"predicate\"])\n",
    "                asp.append(list_dct[k][\"aspect\"])\n",
    "                lab.append(type_of_compare.index(list_dct[k][\"label\"]) + 1)\n",
    "            if len(sentence_label) > 1:\n",
    "                full_label = []\n",
    "                l = 0\n",
    "                for n in range(len(sentence_label[0])):\n",
    "                    for j in range(len(sentence_label) - 1):\n",
    "                        if sentence_label[j][n] == sentence_label[j + 1][n]:\n",
    "                            l = sentence_label[j][n]\n",
    "                        elif sentence_label[j][n] != sentence_label[j + 1][n]:\n",
    "                            if sentence_label[j][n] == 0:\n",
    "                                l = sentence_label[j + 1][n]\n",
    "                            elif sentence_label[j + 1][n] == 0:\n",
    "                                l = sentence_label[j][n]\n",
    "                    full_label.append(l)\n",
    "                sentence_label = full_label\n",
    "                del full_label\n",
    "            else:\n",
    "                sentence_label = label\n",
    "        else:\n",
    "            sentence_label = label\n",
    "        data_frame[\"content\"].append(\" \".join(smted))\n",
    "        data_frame[\"comparative\"].append(key)\n",
    "        data_frame[\"subject\"].append(subj)\n",
    "        data_frame[\"object\"].append(obj)\n",
    "        data_frame[\"predicate\"].append(pred)\n",
    "        data_frame[\"aspect\"].append(asp)\n",
    "        data_frame[\"label\"].append(lab)\n",
    "        data_frame[\"NER\"].append(sentence_label)\n",
    "        for j in range(len(pred)):\n",
    "            if pred[j] not in pred_label.keys():\n",
    "                pred_label[pred[j]] = [lab[j]]\n",
    "            elif pred[j] in pred_label.keys() and lab[j] not in pred_label[pred[j]]:\n",
    "                pred_label[pred[j]].append(lab[j])\n",
    "    return data_frame\n",
    "for i in only_files:\n",
    "    preprocessing_with_BIO(i)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T15:55:02.824721Z",
     "start_time": "2023-10-24T15:54:48.013279500Z"
    }
   },
   "id": "d39c0d1fa793aaa0"
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "train_0013 16 15 ['Mặt', 'lưng', 'với', 'hoạ_tiết', 'cắt', 'kim_cương', 'đa', 'sắc', 'nổi_bật', 'với', '4', 'tuỳ', 'chọn', 'màu_sắc', 'sành_điệu', ':'] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]['Mặt', 'lưng', 'với', 'họa', 'tiết', 'cắt', 'kim', 'cương', 'đa', 'sắc', 'nổi', 'bật', 'với', '4', 'tùy', 'chọn', 'màu', 'sắc', 'sành', 'điệu', ':', 'Xanh', ',', 'Trắng', ',', 'Đen', ',', 'Bạc', '.']\n",
      "train_0016 16 15 ['Tuỳ', 'phong_cách', 'mà', 'người', 'sử_dụng', 'có_thể', 'lựa_chọn', 'cho', 'mình', 'phiên_bản', 'màu', 'Galaxy', 'A24', 'phù_hợp', 'nhất', '.'] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]['Tùy', 'phong', 'cách', 'mà', 'người', 'sử', 'dụng', 'có', 'thể', 'lựa', 'chọn', 'cho', 'mình', 'phiên', 'bản', 'màu', 'Galaxy', 'A24', 'phù', 'hợp', 'nhất', '.']\n",
      "train_0016 20 19 ['Tại', 'Việt_Nam', ',', 'Galaxy', 'A24', 'được', 'bán', 'kèm', 'RAM', 'tuỳ', 'chọn', '6GB', 'hoặc', '8GB', 'đi', 'kèm', 'với', 'bộ_nhớ_trong', '128GB', '.'] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]['Tại', 'Việt', 'Nam', ',', 'Galaxy', 'A24', 'được', 'bán', 'kèm', 'RAM', 'tùy', 'chọn', '6GB', 'hoặc', '8GB', 'đi', 'kèm', 'với', 'bộ', 'nhớ', 'trong', '128GB', '.']\n",
      "train_0016 25 24 ['Về', 'phần_mềm', 'máy', 'được', 'cài', 'sẵn', 'hệ_điều_hành', 'Android', '13', 'với', 'tuỳ', 'biến', 'giao_diện', 'OneUI', '5.1', 'đưa', 'tới', 'những', 'trải_nghiệm', 'hiện_đại', 'nhất', 'cho', 'người', 'sử_dụng', '.'] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]['Về', 'phần', 'mềm', 'máy', 'được', 'cài', 'sẵn', 'hệ', 'điều', 'hành', 'Android', '13', 'với', 'tùy', 'biến', 'giao', 'diện', 'OneUI', '5.1', 'đưa', 'tới', 'những', 'trải', 'nghiệm', 'hiện', 'đại', 'nhất', 'cho', 'người', 'sử', 'dụng', '.']\n",
      "train_0017 36 35 ['Tuỳ', 'theo', 'nhu_cầu', 'sử_dụng', 'mà', 'người', 'dùng', 'có_thể', 'chọn', 'mẫu', 'máy', 'phù_hợp', 'nhất', 'nhưng', 'nhìn_chung', ',', 'cả', 'hai', 'camera', 'của', 'hai', 'dòng', 'máy', 'mới', 'nên', 'trên', 'đều', 'đảm_bảo', 'chất_lượng', ',', 'xử_lý', 'hầu_hết', 'mọi', 'tác_vụ', 'nhiếp_ảnh', '.'] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]['Tùy', 'theo', 'nhu', 'cầu', 'sử', 'dụng', 'mà', 'người', 'dùng', 'có', 'thể', 'chọn', 'mẫu', 'máy', 'phù', 'hợp', 'nhất', 'nhưng', 'nhìn', 'chung', ',', 'cả', 'hai', 'camera', 'của', 'hai', 'dòng', 'máy', 'mới', 'nên', 'trên', 'đều', 'đảm', 'bảo', 'chất', 'lượng', ',', 'xử', 'lý', 'hầu', 'hết', 'mọi', 'tác', 'vụ', 'nhiếp', 'ảnh', '.']\n"
     ]
    }
   ],
   "source": [
    "print(len(error))\n",
    "for i in range(5):\n",
    "    print(error[i])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T15:55:07.159196800Z",
     "start_time": "2023-10-24T15:55:07.152173100Z"
    }
   },
   "id": "67db2b7efc89f248"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "import csv  \n",
    "# name of csv file  \n",
    "filename = \"predicate_label_dictionary.csv\"\n",
    "row = []\n",
    "# writing to csv file  \n",
    "with open(filename, 'w', encoding=\"utf-8\") as csvfile:  \n",
    "    csvwriter = csv.writer(csvfile)  \n",
    "    csvwriter.writerow([\"Word\",\"Label\"])  \n",
    "    for i in pred_label.keys():\n",
    "        row = [i]\n",
    "        row.append(pred_label[i])\n",
    "        csvwriter.writerows([row]) \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T04:39:08.175027400Z",
     "start_time": "2023-10-22T04:39:08.164786100Z"
    }
   },
   "id": "f9354ed60f13f0d1"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/total.csv')\n",
    "compared = df[df['comparative'] == 1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T10:45:30.424780800Z",
     "start_time": "2023-10-25T10:45:30.405011900Z"
    }
   },
   "id": "70d19b00105b5971"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "smted = segmenter.word_segment(i)[0].split()\n",
    "        j = 0\n",
    "        space = 0\n",
    "        er = 0\n",
    "        temp_ner = []\n",
    "        while j < len(smted):\n",
    "            un = smted[j].split(\"_\")\n",
    "            for u in range(len(un)):\n",
    "                for s in special_char.keys():\n",
    "                    if re.match('^\\w+'+s+'$',un[u]):\n",
    "                        un[u] = un[u].replace(s,special_char[s])\n",
    "            comparing = '_'.join(un)\n",
    "            if w[j+space-er] in comparing and len(w[j+space-er]) <= len(comparing):\n",
    "                temp_ner.append(sentence_label[j+space-er])\n",
    "                if comparing.split('_')[0] != \"\":\n",
    "                    unseg = comparing.split(\"_\")\n",
    "                    counter = 0\n",
    "                    for k in range(len(unseg)-1):\n",
    "                        if abs((sentence_label[j+space-er+k+1] - sentence_label[j+space-er+k])) > 1:\n",
    "                            smentederr.append(filename+','+w.__str__()+','+smted.__str__() + ',' + str(sentence_label[j+space-er+k+1]) + ',' + str(sentence_label[j+space-er+k])+','+str(j)+','+str(k))\n",
    "                            counter += 1\n",
    "                    space += len(unseg)-1\n",
    "            elif comparing in w[j+space-er] and len(comparing) < len(w[j+space-er]):\n",
    "                aim = len(w[j+space-er])\n",
    "                origin = comparing\n",
    "                k = 1\n",
    "                temp_ner.append(sentence_label[j+space-er])\n",
    "                while len(origin) < aim:\n",
    "                    origin += smted[j+k]\n",
    "                    k += 1\n",
    "                    temp_ner.append(sentence_label[j+space-er])\n",
    "                j += k-1\n",
    "                er += k-1\n",
    "            j+=1\n",
    "        sentence_label = temp_ner"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5fec6ebbee04ffb0"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "d = {'content':[], 'NER':[], 'label':[]}\n",
    "generror = []\n",
    "for k in range(1,9):\n",
    "    df_comp = df_splited[df_splited['label'] == k]\n",
    "    others = df_comp[['subject','object','aspect','NER']]\n",
    "    content = df_comp.to_dict(orient='list')['content']\n",
    "    pred = df_comp.to_dict(orient='list')['predicate']\n",
    "    i = 0\n",
    "    count = 0\n",
    "    while count < 10000:\n",
    "        stg = content[i] \n",
    "        su = others.iloc[i]['subject']\n",
    "        ob = others.iloc[i]['object']\n",
    "        asp = others.iloc[i]['aspect']\n",
    "        pr = pred[i]\n",
    "        n = others.iloc[i]['NER']\n",
    "        # p = random.choice(list(vocab['predicate'].keys()))\n",
    "        # f = pr.split()\n",
    "        # substitute = p.split()\n",
    "        # checkpoint = finder(stg,f)\n",
    "        # n = n[:checkpoint[0]]+[4 for p in range(len(substitute))]+ n[checkpoint[1]+1:]\n",
    "        # stg = stg.replace(pr, p)\n",
    "        if su != '' and su in stg:\n",
    "            f = su.split()\n",
    "            sub = random.choice(list(vocab['subject']))  \n",
    "            substitute = sub.split()\n",
    "            checkpoint = finder(stg,f)\n",
    "            stg = stg.replace(su, sub)\n",
    "            n = n[:checkpoint[0]]+[1 for p in range(len(substitute))]+ n[checkpoint[1]+1:]\n",
    "            # if len(stg.split()) != len(n):\n",
    "            #     a = 's'\n",
    "        if ob != '' and ob in stg:\n",
    "            f = ob.split()\n",
    "            obj = random.choice(list(vocab['object']))\n",
    "            substitute = obj.split()\n",
    "            checkpoint = finder(stg, f)\n",
    "            stg = stg.replace(ob, obj)\n",
    "            n = n[:checkpoint[0]]+[2 for p in range(len(substitute))]+ n[checkpoint[1]+1:]\n",
    "            # if len(stg.split()) != len(n):\n",
    "            #     a = 's'\n",
    "        if asp != '' and asp in stg:\n",
    "            f = asp.split()\n",
    "            aspe = random.choice(list(vocab['aspect']))\n",
    "            substitute = aspe.split()\n",
    "            checkpoint = finder(stg,f)\n",
    "            stg = stg.replace(asp, aspe)\n",
    "            n = n[:checkpoint[0]]+[3 for p in range(len(substitute))]+ n[checkpoint[1]+1:]\n",
    "            # if len(stg.split()) != len(n):\n",
    "            #     a = 's'\n",
    "        if len(stg.split()) != len(n):\n",
    "            generror.append(stg+','+n.__str__()+','+str(k))\n",
    "        if stg not in content:\n",
    "            d['content'].append(stg)\n",
    "            d['NER'].append(n)\n",
    "            d['label'].append(k)\n",
    "            count += 1\n",
    "        i += 1\n",
    "        if i == stat[k]:\n",
    "            i = 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T10:48:00.408717200Z",
     "start_time": "2023-10-25T10:47:51.678729800Z"
    }
   },
   "id": "d0af5b976ad80f1"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2081, 1714, 1866, 3948, 2050, 1991, 1773, 1201]\n",
      "[0, 58, 286, 106, 5, 4, 499, 107, 20, 0]\n"
     ]
    }
   ],
   "source": [
    "counter = [0,0,0,0,0,0,0,0,0]\n",
    "count = 0\n",
    "for i in range(len(generror)):\n",
    "    counter[int(generror[i][-1])] += 1\n",
    "print(counter)\n",
    "print(stat)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T10:48:09.211392500Z",
     "start_time": "2023-10-25T10:48:09.191140900Z"
    }
   },
   "id": "9a99906de87c27b5"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             content  \\\n0  Riêng về dung lượng thì thực sự hiếm có cả ha...   \n1  chụp hình selfie cũng có sự thay đổi đáng kể ,...   \n2  Rõ ràng , sẽ có một khoảng cách về dung lượng ...   \n3  Rõ ràng , sẽ có một khoảng cách về tốc độ xử l...   \n4  Nếu như trên biến thể ultra và các thương ...   \n\n                                                 NER  label  \n0  [0, 0, 3, 3, 0, 0, 0, 4, 4, 2, 2, 2, 2, 4, 4, ...      1  \n1  [3, 3, 3, 0, 0, 4, 4, 4, 4, 4, 0, 0, 0, 1, 1, ...      1  \n2  [0, 0, 0, 0, 4, 4, 4, 4, 0, 3, 3, 3, 3, 0, 3, ...      1  \n3  [0, 0, 0, 0, 4, 4, 4, 4, 0, 3, 3, 3, 3, 0, 3, ...      1  \n4  [0, 0, 0, 1, 1, 1, 0, 2, 2, 2, 2, 0, 0, 4, 4, ...      1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>NER</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Riêng về dung lượng thì thực sự hiếm có cả ha...</td>\n      <td>[0, 0, 3, 3, 0, 0, 0, 4, 4, 2, 2, 2, 2, 4, 4, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>chụp hình selfie cũng có sự thay đổi đáng kể ,...</td>\n      <td>[3, 3, 3, 0, 0, 4, 4, 4, 4, 4, 0, 0, 0, 1, 1, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Rõ ràng , sẽ có một khoảng cách về dung lượng ...</td>\n      <td>[0, 0, 0, 0, 4, 4, 4, 4, 0, 3, 3, 3, 3, 0, 3, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Rõ ràng , sẽ có một khoảng cách về tốc độ xử l...</td>\n      <td>[0, 0, 0, 0, 4, 4, 4, 4, 0, 3, 3, 3, 3, 0, 3, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Nếu như trên biến thể ultra và các thương ...</td>\n      <td>[0, 0, 0, 1, 1, 1, 0, 2, 2, 2, 2, 0, 0, 4, 4, ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_generate = pd.DataFrame(data=d)\n",
    "df_generate.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T11:11:47.528425200Z",
     "start_time": "2023-10-25T11:11:47.447477600Z"
    }
   },
   "id": "7f479116d4838a86"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 content  \\\n59591  kính gorilla ở cả hai mặt trên hai bộ vi xử lý...   \n62869  các thông số kỹ thuật sạc trên samsung z fold ...   \n60553  camera selfie galaxy s22 ultra 5g đúng như tên...   \n10401  des : Nhìn chung camera tele không có sự khác ...   \n22102  Không những vậy , chiếc điện thoại gập cũng...   \n\n                                                     NER  label  \n59591  [3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 1, 1, 1, 0, 0, ...      8  \n62869  [3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 1, 0, 0, 4, 4, ...      8  \n60553  [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      8  \n10401            [0, 0, 0, 0, 1, 1, 4, 4, 4, 4, 4, 4, 4]      2  \n22102  [0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...      3  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>NER</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>59591</th>\n      <td>kính gorilla ở cả hai mặt trên hai bộ vi xử lý...</td>\n      <td>[3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 1, 1, 1, 0, 0, ...</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>62869</th>\n      <td>các thông số kỹ thuật sạc trên samsung z fold ...</td>\n      <td>[3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 1, 0, 0, 4, 4, ...</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>60553</th>\n      <td>camera selfie galaxy s22 ultra 5g đúng như tên...</td>\n      <td>[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>10401</th>\n      <td>des : Nhìn chung camera tele không có sự khác ...</td>\n      <td>[0, 0, 0, 0, 1, 1, 4, 4, 4, 4, 4, 4, 4]</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>22102</th>\n      <td>Không những vậy , chiếc điện thoại gập cũng...</td>\n      <td>[0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shuffled = df_generate.sample(len(df_generate), random_state=1)\n",
    "df_shuffled.to_csv('Data/generated_data.csv')\n",
    "df_shuffled.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T11:33:28.953506400Z",
     "start_time": "2023-10-25T11:33:28.530911900Z"
    }
   },
   "id": "8ecdd87cb491163b"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 7919, 8286, 8134, 6052, 7950, 8009, 8227, 8799]\n"
     ]
    }
   ],
   "source": [
    "counter = [0,0,0,0,0,0,0,0,0]\n",
    "for i in range(len(d['content'])):\n",
    "    counter[d['label'][i]] += 1\n",
    "print(counter)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T11:23:15.276382900Z",
     "start_time": "2023-10-25T11:23:15.251767500Z"
    }
   },
   "id": "9e92f1161276d4dd"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'zip' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[20], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m gen_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(d[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m'\u001B[39m],d[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNER\u001B[39m\u001B[38;5;124m'\u001B[39m],d[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m----> 2\u001B[0m \u001B[43mrandom\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshuffle\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgen_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m c \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m      4\u001B[0m wrt \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m'\u001B[39m:[],\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNER\u001B[39m\u001B[38;5;124m'\u001B[39m:[],\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m'\u001B[39m:[]}\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Lib\\random.py:380\u001B[0m, in \u001B[0;36mRandom.shuffle\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    377\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Shuffle list x in place, and return None.\"\"\"\u001B[39;00m\n\u001B[0;32m    379\u001B[0m randbelow \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_randbelow\n\u001B[1;32m--> 380\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mreversed\u001B[39m(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)):\n\u001B[0;32m    381\u001B[0m     \u001B[38;5;66;03m# pick an element in x[:i+1] with which to exchange x[i]\u001B[39;00m\n\u001B[0;32m    382\u001B[0m     j \u001B[38;5;241m=\u001B[39m randbelow(i \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    383\u001B[0m     x[i], x[j] \u001B[38;5;241m=\u001B[39m x[j], x[i]\n",
      "\u001B[1;31mTypeError\u001B[0m: object of type 'zip' has no len()"
     ]
    }
   ],
   "source": [
    "gen_data = zip(d['content'],d['NER'],d['label'])\n",
    "random.shuffle(gen_data)\n",
    "c = 0\n",
    "wrt = {'content':[],'NER':[],'label':[]}\n",
    "for c, n, l in gen_data:\n",
    "    if len(c.split()) != len(n):\n",
    "        c+=1\n",
    "    else:\n",
    "        wrt['content'].append(c)\n",
    "        wrt['NER'].append(n)\n",
    "        wrt['label'].append(l)\n",
    "\n",
    "print(c)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T11:07:25.258938900Z",
     "start_time": "2023-10-25T11:07:25.208016400Z"
    }
   },
   "id": "113824abf13c5635"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<zip object at 0x0000018C35372F40>\n"
     ]
    }
   ],
   "source": [
    "print(gen_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T11:00:05.428330100Z",
     "start_time": "2023-10-25T11:00:05.387535800Z"
    }
   },
   "id": "8ce298daad86a9c4"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuy nhiên chúng vẫn có những điểm đều được trang bị như camera selfie của hai model này be shown so với màn hình 6,8 inch của biến thể ultra và hỗ trợ sạc cũng có sự đều được trang bị . [0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 0, 3, 3, 3, 0, 0, 1, 1, 1, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 3, 3, 3, 0, 0, 0, 4, 4, 0] 42 43\n",
      "phần cứng camera sau cũng có không có nhiều thay đổi , đối với iphone 13 pro max lên đến 6GB . [3, 3, 3, 3, 0, 0, 4, 4, 4, 4, 4, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0] 22 22\n",
      "Rõ ràng , sẽ thú vị nhất về những bức ảnh , khả năng đồ họa và khả năng tiết kiệm năng lượng giữa một chiếc máy cao cấp . [0, 0, 0, 0, 4, 4, 4, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 1, 1, 2, 2, 2, 0, 0, 0, 0, 4, 4, 4, 4, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 1, 1, 0] 30 64\n",
      "Rõ ràng , sẽ vượt trội hơn về tốc độ xử lý , chip xử lý snapdragon 8 gen 2 của qualcomm và khả năng tiết kiệm năng lượng giữa máy . [0, 0, 0, 0, 4, 4, 4, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 0, 1, 2, 2, 2, 0, 0, 0, 0, 4, 4, 4, 4, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 0, 1, 0] 32 62\n",
      "Rõ ràng , sẽ tốt hơn rất nhiều về tốc độ xử lý , khả năng đồ họa và dung lượng pin giữa thiết bị tới từ apple . [0, 0, 0, 0, 4, 4, 4, 4, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 1, 1, 2, 2, 2, 0, 0, 0, 0, 4, 4, 4, 4, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 1, 1, 0] 29 67\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(d['content'][i],d['NER'][i],len(d['content'][i].split()), len(d['NER'][i]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T07:11:24.514229800Z",
     "start_time": "2023-10-25T07:11:24.487298700Z"
    }
   },
   "id": "99c788b087cb26fc"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "['.idea',\n 'Data',\n 'Data preprocessing.ipynb',\n 'label_1.txt',\n 'modelUtils.py',\n 'predicate_label_dictionary.csv',\n 'Preprocessing.py',\n 'vncorenlp',\n '__pycache__']"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T08:51:27.523389300Z",
     "start_time": "2023-10-23T08:51:27.505539100Z"
    }
   },
   "id": "da13a6a0f9001f06"
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "for i in range(1,len(lst)):\n",
    "    name = 'ccmparison_label_'+str(i)+'.txt'\n",
    "    with open(name, 'w', encoding=\"utf-8\") as resamplingfile:\n",
    "        for j in range(len(lst[i])):\n",
    "            resamplingfile.write(lst[i][j]+'\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T01:43:29.031384Z",
     "start_time": "2023-10-23T01:43:29.018304500Z"
    }
   },
   "id": "d55a5fb57b52c2b3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
