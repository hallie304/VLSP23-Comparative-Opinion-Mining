{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKg-fOmR_QVA",
        "outputId": "0dbf61b3-de57-431c-aeb5-d6529797eb9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.1/612.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.21.0 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "%pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9uB9jvZCUby",
        "outputId": "b8603919-6ea2-4097-b27d-bb85b1ccc7fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-keaxolxn\n",
            "  Running command git clone --filter=blob:none --quiet https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-keaxolxn\n",
            "  warning: redirecting to https://github.com/keras-team/keras-contrib.git/\n",
            "  Resolved https://www.github.com/keras-team/keras-contrib.git to commit 3fc5ef709e061416f4bc8a92ca3750c824b5d2b0\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-contrib==2.0.8) (2.13.1)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-py3-none-any.whl size=101055 sha256=73438aca73207db849588d4c1d14ac117ca3c41067193b7dc6d64a71a30bd11e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-t19cdpny/wheels/74/d5/f7/0245af7ac33d5b0c2e095688649916e4bf9a8d6b3362a849f5\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n"
          ]
        }
      ],
      "source": [
        "! pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0SCbgNuuwWF",
        "outputId": "f69b3b1c-9650-47cd-ad30-2a45813c7937"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import re\n",
        "import keras\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "import tensorflow_addons\n",
        "from keras_contrib.layers import CRF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfPLGuv5u9Pk"
      },
      "outputs": [],
      "source": [
        "#Reading the csv file\n",
        "df = pd.read_csv('/content/demo_ner2.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "biPUDQ9Kwj8_"
      },
      "outputs": [],
      "source": [
        "X_data = df.Sentence\n",
        "y_data = df.Label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5xMumlX360n",
        "outputId": "6b94698e-ede3-4f32-bc89-9deb9c6b2970"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, ...\n",
              "1        [1, 4, 4, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0]\n",
              "2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, ...\n",
              "3        [1, 4, 4, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0]\n",
              "4    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, ...\n",
              "5        [1, 4, 4, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0]\n",
              "6    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, ...\n",
              "7        [1, 4, 4, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0]\n",
              "8    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, ...\n",
              "9        [1, 4, 4, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0]\n",
              "Name: Label, dtype: object"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GPyPXj8yGXZ0",
        "outputId": "7143a5cd-2e0c-4aa4-9ab6-1bd6923b1606"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tuy_nhiên , điểm đáng_giá là chi_tiết được tái_tạo rất chân_thực , không bị gai_góc như_trên Samsung .'"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-55j7E_xLom"
      },
      "outputs": [],
      "source": [
        "# Define a function to extract words and punctuation from a sentence\n",
        "def extract_words_and_punctuation(sentence):\n",
        "    words_and_punctuation = re.findall(r'\\w+|[.,!?;]', sentence.lower())  # Split on words and punctuation marks\n",
        "    return words_and_punctuation\n",
        "\n",
        "# Apply the function to each row of the \"Sentence\" column and store the results in a list\n",
        "unique_words_and_punctuation = set()\n",
        "for sentence in df['Sentence']:\n",
        "    words_and_punctuation = extract_words_and_punctuation(sentence)\n",
        "    unique_words_and_punctuation.update(words_and_punctuation)\n",
        "\n",
        "# Convert the set of unique words and punctuation marks back to a list\n",
        "unique_words_list = list(unique_words_and_punctuation)\n",
        "\n",
        "word_to_index = {w : i + 2 for i, w in enumerate(unique_words_list)}\n",
        "word_to_index[\"UNK\"] = 1\n",
        "word_to_index[\"PAD\"] = 0\n",
        "idx2word = {i: w for w, i in word_to_index.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYHV2y-y2QxM",
        "outputId": "225ff82f-218c-4f98-9df5-e0f496bb2811"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{2: 'như_trên',\n",
              " 3: 'tuy_nhiên',\n",
              " 4: 'thông_số',\n",
              " 5: 'điểm',\n",
              " 6: 'cho_đến',\n",
              " 7: 'gai_góc',\n",
              " 8: 'không',\n",
              " 9: 'được',\n",
              " 10: 'ip68',\n",
              " 11: '.',\n",
              " 12: 'tốt',\n",
              " 13: 'cả_hai',\n",
              " 14: 'chân_thực',\n",
              " 15: 'đều',\n",
              " 16: 'sở_hữu',\n",
              " 17: 'samsung',\n",
              " 18: 'cao_cấp',\n",
              " 19: ',',\n",
              " 20: 'là',\n",
              " 21: 'cường_lực',\n",
              " 22: 'bảo_vệ',\n",
              " 23: 'bị',\n",
              " 24: 'kính',\n",
              " 25: 'từ',\n",
              " 26: 'tái_tạo',\n",
              " 27: 'rất',\n",
              " 28: 'những',\n",
              " 29: 'chi_tiết',\n",
              " 30: 'đáng_giá',\n",
              " 1: 'UNK',\n",
              " 0: 'PAD'}"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "idx2word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R33XHygb3bAp",
        "outputId": "efa42a24-7574-4612-c0ab-da643d72beed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-93-75d574d446e0>:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  X_indexed = np.array([sentence_to_indexes(sentence, word_to_index) for sentence in X_data])\n"
          ]
        }
      ],
      "source": [
        "# Define a function to convert a sentence to a list of indexes\n",
        "def sentence_to_indexes(sentence, word_to_index):\n",
        "    words = sentence.lower().split()  # Split sentence into words and convert to lowercase\n",
        "    indexes = [word_to_index.get(word, word_to_index[\"UNK\"]) for word in words]\n",
        "    return indexes\n",
        "\n",
        "# Apply the function to each element in the array X and store the results in a new list\n",
        "X_indexed = np.array([sentence_to_indexes(sentence, word_to_index) for sentence in X_data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sr8PxL1Cxc_v"
      },
      "outputs": [],
      "source": [
        "# Padding each sequence to have same length  of each word\n",
        "X_pad = pad_sequences(maxlen = 128, sequences = X_indexed, padding = \"post\", value = word_to_index[\"PAD\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5uII8RUJ6E2",
        "outputId": "8f8c59f9-1251-4753-c53b-efdf044df127"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 3, 19,  5, 30, 20, 29,  9, 26, 27, 14, 19,  8, 23,  7,  2, 17, 11,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0], dtype=int32)"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_pad[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-sBAUAG324Q",
        "outputId": "740251de-89ac-4177-bb4d-3dfd0b864475"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-17-389b7664c8fa>:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  y_indexed = np.array([np.array(lst) for lst in y_indexed])\n"
          ]
        }
      ],
      "source": [
        "import ast\n",
        "y_indexed = [ast.literal_eval(y_str) for y_str in y_data]\n",
        "y_indexed = np.array([np.array(lst) for lst in y_indexed])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FE0Cq1qV6PBB"
      },
      "outputs": [],
      "source": [
        "y_pad = pad_sequences(maxlen = 128, sequences = y_indexed, padding = \"post\", value = word_to_index[\"PAD\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiSkn3f87nXj",
        "outputId": "a59c009c-5727-410b-ade0-910b338c64cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 2, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pad[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgQSBvnp7UPz"
      },
      "outputs": [],
      "source": [
        "y_categorical = np.array([to_categorical(i, num_classes = 5) for i in y_pad])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWt4ZiW274Rn",
        "outputId": "fdd50618-7f4b-4f45-fc3d-a88bd02d4a90"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_categorical[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kbhn0NVY8WwZ"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_pad, y_categorical, test_size = 0.15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5upnQ59DD23",
        "outputId": "d45b5d58-ecda-42fd-bcf1-21ade6466e8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10, 128, 5)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQRddnXWDkXH",
        "outputId": "48814d54-cb9f-4ee0-f182-a4eed2f5d190"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10, 128)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-kpeeCb8qsT",
        "outputId": "b57a9699-e182-4d83-f7f3-89a3253dc9ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 128)]             0         \n",
            "                                                                 \n",
            " embedding_7 (Embedding)     (None, 128, 128)          3968      \n",
            "                                                                 \n",
            " bidirectional_7 (Bidirecti  (None, 128, 128)          98816     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 128, 128)          16512     \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 128, 5)            645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 119941 (468.52 KB)\n",
            "Trainable params: 119941 (468.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# num_tags = df['Tag'].nunique()\n",
        "# Model architecture\n",
        "embedding = 128\n",
        "max_len = 128\n",
        "input = tf.keras.Input(shape = (max_len,))\n",
        "model = tf.keras.layers.Embedding(input_dim = len(unique_words_list) + 2, output_dim = embedding, input_length = max_len)(input)\n",
        "model = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units = 64, return_sequences=True, recurrent_dropout=0.1))(model)\n",
        "# model = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(100, activation=\"relu\"))(model)\n",
        "model = tf.keras.layers.Dense(128, activation='relu')(model)\n",
        "#crf = CRF(5)\n",
        "#out = crf(model)\n",
        "out = tf.keras.layers.Dense(5, activation='softmax')(model)  # output\n",
        "\n",
        "model = tf.keras.Model(input, out)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJ4-OKxlE6LX",
        "outputId": "071e7728-4735-4956-e44f-3d37bc7cf2d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "1/1 [==============================] - 8s 8s/step - loss: 1.6799 - accuracy: 0.0063\n",
            "Epoch 2/8\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 1.6178 - accuracy: 0.0523\n",
            "Epoch 3/8\n",
            "1/1 [==============================] - 1s 881ms/step - loss: 1.5671 - accuracy: 0.9547\n",
            "Epoch 4/8\n",
            "1/1 [==============================] - 1s 888ms/step - loss: 1.5281 - accuracy: 0.9547\n",
            "Epoch 5/8\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.4855 - accuracy: 0.9547\n",
            "Epoch 6/8\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.4355 - accuracy: 0.9547\n",
            "Epoch 7/8\n",
            "1/1 [==============================] - 1s 895ms/step - loss: 1.3751 - accuracy: 0.9547\n",
            "Epoch 8/8\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 1.3010 - accuracy: 0.9547\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "epochs = 8\n",
        "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXOkO8WwJbAs",
        "outputId": "fcb0c9e6-b445-4554-b2b6-77e7e54c8bfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 1s/step - loss: 1.2774 - accuracy: 0.9453\n",
            "Test Loss: 1.2774338722229004\n",
            "Test Accuracy: 0.9453125\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print('Test Loss:', test_loss)\n",
        "print('Test Accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pueMaYEPkJ8"
      },
      "outputs": [],
      "source": [
        "test_x_text = \"chi_tiết đáng_giá từ adsadsadada\"\n",
        "test_x = np.array([sentence_to_indexes(test_x_text, word_to_index)])\n",
        "test_x_pad = pad_sequences(maxlen = 128, sequences = test_x, padding = \"post\", value = word_to_index[\"PAD\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fZlZalmPl-M",
        "outputId": "b39ef99a-9920-4e6c-ffee-bc32c7e5101a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[29, 30, 25,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
              "      dtype=int32)"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_x_pad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dzl_YdNjPB-o",
        "outputId": "d5bae8d1-0ab1-4d7c-8cfc-3a22a641c84c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 179ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[[0.23646177, 0.20616342, 0.1896774 , 0.19182476, 0.17587258],\n",
              "        [0.24170369, 0.20678662, 0.18753983, 0.19104694, 0.17292298],\n",
              "        [0.24533474, 0.20743977, 0.1874896 , 0.19052814, 0.16920777],\n",
              "        [0.24907276, 0.20907164, 0.18972582, 0.18639438, 0.16573535],\n",
              "        [0.25915286, 0.20798592, 0.18781537, 0.18568207, 0.15936375],\n",
              "        [0.26302603, 0.20823044, 0.18657848, 0.18391576, 0.15824926],\n",
              "        [0.26632786, 0.2082697 , 0.18570124, 0.18207824, 0.15762307],\n",
              "        [0.2694714 , 0.20816454, 0.18492945, 0.18028307, 0.15715156],\n",
              "        [0.27257276, 0.208116  , 0.18430354, 0.17841718, 0.15659052],\n",
              "        [0.27536625, 0.20808777, 0.18366344, 0.17681083, 0.1560717 ],\n",
              "        [0.27768642, 0.2080595 , 0.183149  , 0.17545292, 0.15565223],\n",
              "        [0.27967486, 0.2079738 , 0.18273918, 0.17427948, 0.15533267],\n",
              "        [0.28134614, 0.20775242, 0.18248592, 0.17335285, 0.15506266],\n",
              "        [0.28280547, 0.2076624 , 0.18219477, 0.17254849, 0.15478884],\n",
              "        [0.28407374, 0.207702  , 0.181874  , 0.171814  , 0.15453626],\n",
              "        [0.2850418 , 0.20773938, 0.18171063, 0.17110126, 0.15440701],\n",
              "        [0.28583613, 0.20775451, 0.18159012, 0.17053106, 0.1542882 ],\n",
              "        [0.28649408, 0.20777516, 0.18149093, 0.17005172, 0.15418811],\n",
              "        [0.2870384 , 0.20779917, 0.18140908, 0.16964978, 0.1541037 ],\n",
              "        [0.28748825, 0.20782477, 0.18134126, 0.16931324, 0.15403245],\n",
              "        [0.28786004, 0.20785087, 0.18128486, 0.16903183, 0.15397242],\n",
              "        [0.2881653 , 0.20788753, 0.18121795, 0.1688008 , 0.15392841],\n",
              "        [0.28841513, 0.20793554, 0.18113624, 0.16861312, 0.15389998],\n",
              "        [0.28862187, 0.20797853, 0.18106736, 0.16845618, 0.15387604],\n",
              "        [0.2887932 , 0.20801666, 0.18100935, 0.16832483, 0.15385595],\n",
              "        [0.28893545, 0.20805031, 0.18096052, 0.16821477, 0.153839  ],\n",
              "        [0.28905374, 0.20807973, 0.18091944, 0.16812234, 0.15382476],\n",
              "        [0.28915235, 0.20810536, 0.18088491, 0.16804466, 0.15381275],\n",
              "        [0.2892347 , 0.20812751, 0.18085587, 0.16797918, 0.15380266],\n",
              "        [0.28930372, 0.2081466 , 0.1808315 , 0.16792399, 0.15379421],\n",
              "        [0.2893616 , 0.20816296, 0.18081105, 0.1678773 , 0.1537871 ],\n",
              "        [0.28941026, 0.20817691, 0.18079387, 0.16783778, 0.15378115],\n",
              "        [0.2894513 , 0.20818876, 0.18077949, 0.16780429, 0.15377618],\n",
              "        [0.28948596, 0.2081988 , 0.18076742, 0.16777581, 0.15377204],\n",
              "        [0.28951526, 0.20820725, 0.18075728, 0.16775163, 0.15376855],\n",
              "        [0.28953737, 0.2082138 , 0.18074988, 0.16773294, 0.153766  ],\n",
              "        [0.28955454, 0.20821899, 0.1807443 , 0.16771811, 0.15376405],\n",
              "        [0.289569  , 0.2082233 , 0.1807397 , 0.16770557, 0.15376249],\n",
              "        [0.28958115, 0.20822681, 0.18073592, 0.1676949 , 0.15376118],\n",
              "        [0.28959146, 0.20822977, 0.1807328 , 0.16768588, 0.15376014],\n",
              "        [0.28960013, 0.20823216, 0.18073018, 0.1676782 , 0.15375927],\n",
              "        [0.28960752, 0.20823415, 0.1807281 , 0.16767171, 0.15375859],\n",
              "        [0.28961375, 0.20823579, 0.18072632, 0.16766617, 0.15375805],\n",
              "        [0.28961903, 0.20823708, 0.18072486, 0.16766146, 0.15375757],\n",
              "        [0.2896235 , 0.20823818, 0.18072365, 0.16765743, 0.1537572 ],\n",
              "        [0.28962728, 0.20823906, 0.18072267, 0.16765405, 0.15375692],\n",
              "        [0.2896305 , 0.20823978, 0.18072182, 0.16765115, 0.15375666],\n",
              "        [0.28963327, 0.2082404 , 0.18072113, 0.1676487 , 0.15375648],\n",
              "        [0.28963563, 0.20824088, 0.18072057, 0.1676466 , 0.15375632],\n",
              "        [0.2896376 , 0.20824128, 0.18072009, 0.16764481, 0.15375617],\n",
              "        [0.28963932, 0.20824161, 0.1807197 , 0.16764331, 0.15375608],\n",
              "        [0.28964075, 0.20824188, 0.18071936, 0.16764203, 0.15375598],\n",
              "        [0.289642  , 0.20824209, 0.18071912, 0.16764092, 0.15375592],\n",
              "        [0.289643  , 0.20824225, 0.18071887, 0.16763999, 0.15375583],\n",
              "        [0.2896439 , 0.2082424 , 0.18071868, 0.16763921, 0.15375578],\n",
              "        [0.2896447 , 0.20824252, 0.18071853, 0.16763853, 0.15375574],\n",
              "        [0.28964534, 0.20824262, 0.18071844, 0.16763794, 0.1537557 ],\n",
              "        [0.2896459 , 0.20824267, 0.18071835, 0.16763747, 0.15375565],\n",
              "        [0.28964636, 0.20824273, 0.18071827, 0.16763705, 0.15375562],\n",
              "        [0.28964677, 0.20824274, 0.18071824, 0.16763668, 0.15375559],\n",
              "        [0.2896471 , 0.20824274, 0.18071821, 0.16763636, 0.15375553],\n",
              "        [0.28964743, 0.20824274, 0.18071823, 0.16763611, 0.15375552],\n",
              "        [0.28964767, 0.20824273, 0.18071824, 0.16763587, 0.15375546],\n",
              "        [0.2896479 , 0.20824267, 0.18071832, 0.1676357 , 0.15375543],\n",
              "        [0.2896481 , 0.20824261, 0.18071838, 0.1676355 , 0.15375537],\n",
              "        [0.28964826, 0.20824254, 0.1807185 , 0.16763537, 0.15375532],\n",
              "        [0.28964838, 0.20824245, 0.18071865, 0.16763523, 0.15375528],\n",
              "        [0.2896485 , 0.20824231, 0.18071884, 0.16763511, 0.15375523],\n",
              "        [0.28964862, 0.20824213, 0.18071906, 0.16763502, 0.15375519],\n",
              "        [0.28964868, 0.20824192, 0.18071932, 0.16763493, 0.15375513],\n",
              "        [0.2896487 , 0.20824167, 0.18071966, 0.16763489, 0.15375507],\n",
              "        [0.28964874, 0.20824137, 0.18072003, 0.16763486, 0.15375501],\n",
              "        [0.28964874, 0.208241  , 0.18072048, 0.16763483, 0.15375496],\n",
              "        [0.28964868, 0.20824054, 0.180721  , 0.16763484, 0.15375493],\n",
              "        [0.28964856, 0.20823999, 0.18072163, 0.16763487, 0.15375489],\n",
              "        [0.28964844, 0.20823933, 0.18072236, 0.16763496, 0.1537549 ],\n",
              "        [0.28964823, 0.20823856, 0.18072322, 0.16763513, 0.15375492],\n",
              "        [0.2896479 , 0.2082376 , 0.18072422, 0.16763532, 0.15375496],\n",
              "        [0.2896475 , 0.20823646, 0.18072537, 0.1676356 , 0.15375507],\n",
              "        [0.28964692, 0.20823511, 0.18072674, 0.16763602, 0.15375525],\n",
              "        [0.28964615, 0.20823349, 0.18072832, 0.16763654, 0.1537555 ],\n",
              "        [0.28964517, 0.20823155, 0.18073015, 0.16763721, 0.15375589],\n",
              "        [0.28964388, 0.20822926, 0.18073232, 0.1676381 , 0.15375642],\n",
              "        [0.28964224, 0.20822653, 0.18073483, 0.16763924, 0.15375715],\n",
              "        [0.28964013, 0.2082233 , 0.18073775, 0.16764067, 0.15375814],\n",
              "        [0.28963748, 0.20821945, 0.18074115, 0.16764246, 0.15375942],\n",
              "        [0.28963414, 0.20821491, 0.1807451 , 0.16764471, 0.15376109],\n",
              "        [0.28962994, 0.20820954, 0.18074971, 0.16764751, 0.15376328],\n",
              "        [0.28962466, 0.20820321, 0.1807551 , 0.16765097, 0.15376604],\n",
              "        [0.2896181 , 0.20819573, 0.18076137, 0.16765521, 0.15376958],\n",
              "        [0.28960997, 0.20818695, 0.18076867, 0.16766043, 0.15377405],\n",
              "        [0.28959984, 0.20817657, 0.18077718, 0.16766673, 0.15377961],\n",
              "        [0.28958738, 0.20816444, 0.18078713, 0.16767442, 0.15378661],\n",
              "        [0.28957197, 0.20815018, 0.18079871, 0.16768374, 0.15379532],\n",
              "        [0.2895531 , 0.20813353, 0.1808123 , 0.16769499, 0.15380612],\n",
              "        [0.28952992, 0.20811403, 0.18082811, 0.16770847, 0.15381943],\n",
              "        [0.2895016 , 0.20809132, 0.18084663, 0.16772464, 0.1538358 ],\n",
              "        [0.28946704, 0.20806482, 0.18086825, 0.16774394, 0.15385588],\n",
              "        [0.28942502, 0.20803407, 0.18089357, 0.16776697, 0.15388046],\n",
              "        [0.2893739 , 0.20799832, 0.18092315, 0.16779429, 0.1539104 ],\n",
              "        [0.28931195, 0.2079569 , 0.18095775, 0.16782662, 0.1539468 ],\n",
              "        [0.28923696, 0.20790899, 0.1809982 , 0.16786478, 0.15399101],\n",
              "        [0.28914645, 0.2078537 , 0.1810455 , 0.16790979, 0.15404455],\n",
              "        [0.28903735, 0.20779   , 0.18110082, 0.16796263, 0.15410927],\n",
              "        [0.28890598, 0.20771673, 0.1811654 , 0.16802455, 0.15418734],\n",
              "        [0.28874817, 0.20763266, 0.18124078, 0.16809693, 0.15428141],\n",
              "        [0.28855893, 0.20753644, 0.18132874, 0.16818136, 0.15439454],\n",
              "        [0.28833017, 0.20742765, 0.18143022, 0.1682801 , 0.15453184],\n",
              "        [0.2880336 , 0.20731637, 0.18153761, 0.16840038, 0.15471205],\n",
              "        [0.28768185, 0.20718926, 0.18166307, 0.1685394 , 0.15492639],\n",
              "        [0.28726527, 0.20704435, 0.18180954, 0.16869976, 0.15518105],\n",
              "        [0.2867918 , 0.20685765, 0.1819916 , 0.16885808, 0.15550086],\n",
              "        [0.28625438, 0.20661972, 0.18221669, 0.1690091 , 0.15590014],\n",
              "        [0.28561774, 0.20635076, 0.18247707, 0.16918404, 0.15637039],\n",
              "        [0.28483105, 0.20608035, 0.1827763 , 0.1693499 , 0.15696241],\n",
              "        [0.28390542, 0.20577432, 0.18312114, 0.16954412, 0.15765499],\n",
              "        [0.28279328, 0.20544456, 0.18354346, 0.16976036, 0.15845832],\n",
              "        [0.28161216, 0.2051304 , 0.18407199, 0.16984692, 0.15933853],\n",
              "        [0.28024155, 0.20483439, 0.18465431, 0.16993386, 0.16033588],\n",
              "        [0.27863887, 0.20448688, 0.18530919, 0.1700589 , 0.16150624],\n",
              "        [0.27677208, 0.20410536, 0.18603036, 0.17024444, 0.16284779],\n",
              "        [0.2746147 , 0.20376837, 0.18678594, 0.17053775, 0.1642932 ],\n",
              "        [0.2720723 , 0.20336734, 0.1876309 , 0.17091809, 0.1660114 ],\n",
              "        [0.2688585 , 0.20297024, 0.18865126, 0.17130361, 0.16821638],\n",
              "        [0.26511192, 0.20249024, 0.18973653, 0.17182955, 0.17083175],\n",
              "        [0.26077062, 0.2018849 , 0.19085895, 0.17256951, 0.17391609],\n",
              "        [0.25566903, 0.2010304 , 0.19199903, 0.17367812, 0.17762348],\n",
              "        [0.24960716, 0.19984451, 0.19323163, 0.17521761, 0.18209909]]],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(test_x_pad)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
